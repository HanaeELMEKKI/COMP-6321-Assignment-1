{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9kEgF+NWYlR2KN/ddtF7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanaeELMEKKI/COMP-6321-Assignment-1/blob/main/Question3/Implementation_Question_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 3**\n",
        "Design and train two neural networks to tackle the regression and classification\n",
        "tasks in Question 1 and Question 2. Use the same datasets and train-test\n",
        "split ratio. Build and train neural networks using PyTorch. Report on the\n",
        "performance of the NN models, and compare them with the models developed\n",
        "using Linear Regression and Logistic Regression."
      ],
      "metadata": {
        "id": "c-PePICZOtV_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "aSJXMOf_5rfR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification:**"
      ],
      "metadata": {
        "id": "Zfd3I3KM_0Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read cvs file into dataframe\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/HanaeELMEKKI/COMP-6321-Assignment-1/main/Question2/lung_cancer_dataset.csv\")"
      ],
      "metadata": {
        "id": "TyudFtBh7Ek1"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df['GENDER'] = label_encoder.fit_transform(df['GENDER'])\n",
        "df['LUNG_CANCER'] = label_encoder.fit_transform(df['LUNG_CANCER'])"
      ],
      "metadata": {
        "id": "mTUUmbAR7_zb"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalization\n",
        "df_trn, df_tst = train_test_split( df, test_size=0.3)\n",
        "X_trn = df_trn.drop(columns=['LUNG_CANCER'])\n",
        "y_trn = df_trn['LUNG_CANCER']\n",
        "\n",
        "X_tst = df_tst.drop(columns=['LUNG_CANCER'])\n",
        "y_tst = df_tst['LUNG_CANCER']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_trn = scaler.fit_transform(X_trn)\n",
        "X_tst = scaler.transform(X_tst)"
      ],
      "metadata": {
        "id": "DXCUBLWqEbyw"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_trn_torch = torch.tensor (X_trn, dtype=torch.float32)\n",
        "y_trn_torch = torch.tensor (y_trn.values, dtype=torch.float32).reshape(-1, 1)\n",
        "X_tst_torch = torch.tensor (X_tst, dtype=torch.float32)\n",
        "y_tst_torch = torch.tensor (y_tst.values, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "uuw_kz1vvEUZ"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(15, 10),  # Input: 15 features, Output: 10 neurons\n",
        "    nn.ReLU(),  # ReLU activation\n",
        "    nn.Linear(10, 1),  # Input: 10 neurons, Output: 1 for binary classification\n",
        "    nn.Sigmoid()  # Sigmoid activation for binary classification\n",
        ")"
      ],
      "metadata": {
        "id": "DkUcwaiJ8UR-"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "loss_bce = nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the model\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_trn_torch)\n",
        "\n",
        "    loss_value = loss_bce(output, y_trn_torch)  # Compute the loss\n",
        "    loss_value.backward()  # Backpropagation\n",
        "    optimizer.step() #Update weights\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss_value.item()}')"
      ],
      "metadata": {
        "id": "x9LLC0DsAUi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c40c08-ee03-45ab-842f-687dabf5fcde"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.674811601638794\n",
            "Epoch [20/100], Loss: 0.5229834318161011\n",
            "Epoch [30/100], Loss: 0.40118688344955444\n",
            "Epoch [40/100], Loss: 0.3069511651992798\n",
            "Epoch [50/100], Loss: 0.24185284972190857\n",
            "Epoch [60/100], Loss: 0.20142307877540588\n",
            "Epoch [70/100], Loss: 0.17432862520217896\n",
            "Epoch [80/100], Loss: 0.15581637620925903\n",
            "Epoch [90/100], Loss: 0.1427757889032364\n",
            "Epoch [100/100], Loss: 0.13271206617355347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the mode\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_predict = model(X_tst_torch)\n",
        "    predicted = (y_predict.squeeze() > 0.5).float()  # Predicted labels"
      ],
      "metadata": {
        "id": "PUVnDEkgAWb1"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assess the model\n",
        "# Calculate accuracy\n",
        "accuracy = (predicted == y_tst_torch).sum().item() / len(y_tst_torch)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "LAS4MzASAXwu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605b9433-bbd7-41f0-d942-c2d35f741394"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 91.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression**"
      ],
      "metadata": {
        "id": "iI0xDW4Q_5M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read cvs file into dataframe\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/HanaeELMEKKI/COMP-6321-Assignment-1/main/Question1/Health_Insurance_Dataset.csv\")"
      ],
      "metadata": {
        "id": "9Qdt1ggiOQ2R"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df['sex'] = label_encoder.fit_transform(df['sex'])\n",
        "df['region'] = label_encoder.fit_transform(df['region'])\n",
        "df['smoker'] = label_encoder.fit_transform(df['smoker'])"
      ],
      "metadata": {
        "id": "z1w8BzJ4O3uy"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalization\n",
        "df_trn, df_tst = train_test_split( df, test_size=0.3)\n",
        "X_trn = df_trn.drop(columns=['charges'])\n",
        "y_trn = df_trn['charges']\n",
        "\n",
        "X_tst = df_tst.drop(columns=['charges'])\n",
        "y_tst = df_tst['charges']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_trn = scaler.fit_transform(X_trn)\n",
        "X_tst = scaler.transform(X_tst)"
      ],
      "metadata": {
        "id": "ZhlSL89IPCIv"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_trn_torch = torch.tensor (X_trn, dtype=torch.float32)\n",
        "y_trn_torch = torch.tensor (y_trn.values, dtype=torch.float32).reshape(-1, 1)\n",
        "X_tst_torch = torch.tensor (X_tst, dtype=torch.float32)\n",
        "y_tst_torch = torch.tensor (y_tst.values, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "N6hprVD0PLwm"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(6, 1),  # Input: 6 neurons, Output: 1 for regression\n",
        ")"
      ],
      "metadata": {
        "id": "G1RImlenPP66"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "loss_mse = nn.MSELoss()  # Binary Cross Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the model\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_trn_torch)\n",
        "\n",
        "    loss_value = loss_mse(output, y_trn_torch)  # Compute the loss\n",
        "    loss_value.backward()  # Backpropagation\n",
        "    optimizer.step() #Update weights\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss_value.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Fb6-dwPUmL",
        "outputId": "bb5a775b-f85e-4c7e-a0b3-7ddd776e13e4"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 324551136.0\n",
            "Epoch [20/100], Loss: 324544960.0\n",
            "Epoch [30/100], Loss: 324538752.0\n",
            "Epoch [40/100], Loss: 324532576.0\n",
            "Epoch [50/100], Loss: 324526400.0\n",
            "Epoch [60/100], Loss: 324520192.0\n",
            "Epoch [70/100], Loss: 324513952.0\n",
            "Epoch [80/100], Loss: 324507808.0\n",
            "Epoch [90/100], Loss: 324501600.0\n",
            "Epoch [100/100], Loss: 324495424.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the mode\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_predict = model(X_tst_torch)\n",
        "    test_loss = loss_mse(y_predict.squeeze(), y_tst_torch)\n",
        "    print(f'Test Loss: {test_loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHhj4nGWPXPQ",
        "outputId": "c2e12164-61ab-46de-e58a-650dfcd3fb6b"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 318157920.0\n",
            "-31815791900.0% test error\n"
          ]
        }
      ]
    }
  ]
}